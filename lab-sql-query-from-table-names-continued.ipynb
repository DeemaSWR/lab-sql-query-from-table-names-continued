{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [{'role':'system', 'content':\"\"\"\n",
    "-- Table Definitions\n",
    "CREATE TABLE employees (\n",
    "    ID_usr INTEGER PRIMARY KEY,\n",
    "    name VARCHAR(100)\n",
    ");\n",
    "\n",
    "CREATE TABLE salary (\n",
    "    ID_usr INTEGER,\n",
    "    year DATE,\n",
    "    salary FLOAT,\n",
    "    FOREIGN KEY (ID_usr) REFERENCES employees(ID_usr)\n",
    ");\n",
    "\n",
    "CREATE TABLE studies (\n",
    "    ID INTEGER PRIMARY KEY,\n",
    "    ID_usr INTEGER,\n",
    "    educational_level INTEGER,\n",
    "    Institution VARCHAR(100),\n",
    "    Years DATE,\n",
    "    Speciality VARCHAR(100),\n",
    "    FOREIGN KEY (ID_usr) REFERENCES employees(ID_usr)\n",
    ");\n",
    "\n",
    "-- Sample Rows\n",
    "INSERT INTO employees VALUES (1, 'Alice');\n",
    "INSERT INTO employees VALUES (2, 'Bob');\n",
    "INSERT INTO employees VALUES (3, 'Charlie');\n",
    "\n",
    "INSERT INTO salary VALUES (1, '2023-01-01', 70000);\n",
    "INSERT INTO salary VALUES (2, '2023-01-01', 85000);\n",
    "INSERT INTO salary VALUES (3, '2023-01-01', 90000);\n",
    "\n",
    "INSERT INTO studies VALUES (1, 1, 3, 'Ohio University', '2015-06-01', 'Computer Science');\n",
    "INSERT INTO studies VALUES (2, 2, 2, 'Ohio State University', '2018-07-01', 'Economics');\n",
    "INSERT INTO studies VALUES (3, 3, 4, 'MIT', '2012-05-01', 'Physics');\n",
    "\n",
    "-- Few-Shot Sample Queries\n",
    "\n",
    "-- Example query 1\n",
    "-- Get the names of employees earning more than 80000.\n",
    "SELECT e.name\n",
    "FROM employees e\n",
    "JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "WHERE s.salary > 80000;\n",
    "\n",
    "-- Example query 2\n",
    "-- Find all institutions where employees studied.\n",
    "SELECT DISTINCT Institution\n",
    "FROM studies;\n",
    "\n",
    "-- Example query 3\n",
    "-- List employees with educational_level higher than 2.\n",
    "SELECT e.name\n",
    "FROM employees e\n",
    "JOIN studies st ON e.ID_usr = st.ID_usr\n",
    "WHERE st.educational_level > 2;\n",
    "\"\"\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "# FEW SHOT SAMPLES\n",
    "context.append({'role':'system', 'content':\"\"\"\n",
    "-- Maintain the SQL order simple and efficient using valid SQLite syntax. Answer the following types of questions clearly and precisely.\n",
    "\n",
    "-- Example query 4\n",
    "-- Find the highest salary among employees.\n",
    "SELECT MAX(salary) AS highest_salary FROM salary;\n",
    "\n",
    "-- Example query 5\n",
    "-- List all employee names and their respective specialities.\n",
    "SELECT e.name, st.Speciality\n",
    "FROM employees e\n",
    "JOIN studies st ON e.ID_usr = st.ID_usr;\n",
    "\n",
    "-- Example query 6\n",
    "-- How many employees studied at Ohio University?\n",
    "SELECT COUNT(*) AS num_employees\n",
    "FROM studies\n",
    "WHERE Institution = 'Ohio University';\n",
    "\"\"\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT e.name, s.salary\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"List employees and their salaries.\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT employees.name, salary.salary\n",
      "FROM employees\n",
      "JOIN salary ON employees.ID_usr = salary.ID_usr;\n",
      "```\n",
      "\n",
      "This SQL query retrieves the names of employees along with their salaries by joining the \"employees\" table with the \"salary\" table on the common column \"ID_usr\".\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"List employees and their salaries.\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT st.Institution, AVG(s.salary) AS avg_salary\n",
      "FROM studies st\n",
      "JOIN salary s ON st.ID_usr = s.ID_usr\n",
      "GROUP BY st.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 5;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "print(return_CCRMSQL(\"List institutions and the average salary of their graduates, ordered from highest to lowest, showing only the top 5 results.\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM studies s\n",
      "JOIN employees e ON s.ID_usr = e.ID_usr\n",
      "JOIN salary sa ON s.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query joins the tables `studies`, `employees`, and `salary` on the user ID to retrieve the institution with the highest average salary among graduates. It calculates the average salary for each institution, orders the results in descending order, and limits the output to the institution with the highest average salary.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "print(return_CCRMSQL(\"Which institution has graduates with the highest average salary?\", old_context_user))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4ac1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT species, habitat FROM whales;\n",
      "```\n",
      "To find out which whale is the longest, you can use the following SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT species\n",
      "FROM whales\n",
      "ORDER BY length_meters DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This query will retrieve the species of the whale with the longest length in meters from the `whales` table.\n",
      "```sql\n",
      "SELECT species \n",
      "FROM whales \n",
      "WHERE habitat = 'Coastal';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to interact with the OpenAI API\n",
    "def return_CCRMSQL(user_message, context, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    new_context = context.copy()\n",
    "    new_context.append({'role': 'user', 'content': f\"question: {user_message}\"})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=new_context,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define your context with SQL tables related to whales\n",
    "context = [{'role': 'system', 'content': \"\"\"\n",
    "CREATE TABLE whales (\n",
    "    whale_id INTEGER PRIMARY KEY,\n",
    "    species VARCHAR(100),\n",
    "    weight_tons FLOAT,\n",
    "    length_meters FLOAT,\n",
    "    habitat VARCHAR(100)\n",
    ");\n",
    "\n",
    "INSERT INTO whales VALUES (1, 'Blue Whale', 150, 30, 'Oceanic');\n",
    "INSERT INTO whales VALUES (2, 'Humpback Whale', 40, 16, 'Coastal');\n",
    "INSERT INTO whales VALUES (3, 'Beluga Whale', 1.5, 5, 'Arctic');\n",
    "\n",
    "-- Example Queries\n",
    "SELECT species FROM whales WHERE weight_tons > 10;\n",
    "SELECT AVG(length_meters) FROM whales;\n",
    "\"\"\"}]\n",
    "\n",
    "# Test the function with sample queries\n",
    "print(return_CCRMSQL(\"List all whale species and their habitats.\", context))\n",
    "print(return_CCRMSQL(\"Which whale is the longest?\", context))\n",
    "print(return_CCRMSQL(\"Find whales living in Coastal habitats.\", context))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb3d14",
   "metadata": {},
   "source": [
    "### Summary Report: Evaluation of SQL Query Generation with GPT\n",
    "\n",
    "During our exploration of generating SQL queries with GPT, we experimented with different prompt variations centered around whale-themed tables. The goal was to determine the effectiveness and accuracy of GPT-generated SQL queries based on clearly structured, conversational, and creatively engaging prompts.\n",
    "\n",
    "### Variations Tested:\n",
    "1. **Structured and Clear Prompt**\n",
    "   - Clearly defined tables, fields, and concise example queries.\n",
    "   - GPT consistently generated accurate and precise SQL queries, effectively interpreting user intent.\n",
    "\n",
    "2. **Conversational Style Prompt**\n",
    "   - Prompts were casual and intended to mimic natural conversation.\n",
    "   - GPT generally responded well, although minor inaccuracies appeared when conversational prompts lacked precision, occasionally leading to vague interpretations.\n",
    "\n",
    "3. **Creative and Engaging Prompt**\n",
    "   - Employed thematic storytelling to enhance engagement.\n",
    "   - GPT's performance was mixed; while some creative prompts produced accurate queries, others led to slight hallucinations or misinterpretations of the intended request due to ambiguity in the storytelling style.\n",
    "\n",
    "### Variations that Didn't Work Well:\n",
    "- The creative prompt, while engaging, occasionally caused GPT to hallucinate or misinterpret the intent, resulting in minor inaccuracies. Specifically, GPT was less reliable when queries contained ambiguous or highly creative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25616b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "IronhackCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
